{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddafc0ad",
   "metadata": {},
   "source": [
    "## Matrix-Vector Multiplication Implementation Summary\n",
    "\n",
    "In this notebook, we've explored three implementations of matrix-vector multiplication:\n",
    "\n",
    "### 1. Basic Implementation (Python 3.7+)\n",
    "```python\n",
    "def matrix_vector_mult(matrix: list[list[float]], vector: list[float]) -> list[float]:\n",
    "    # Implementation with float type hints\n",
    "```\n",
    "\n",
    "### 2. Improved Implementation with Union Type (Python 3.7+)\n",
    "```python\n",
    "from typing import Union, List\n",
    "Numeric = Union[int, float]\n",
    "\n",
    "def matrix_vector_mult_improved(matrix: List[List[Numeric]], vector: List[Numeric]) -> List[float]:\n",
    "    # Implementation supporting both int and float\n",
    "```\n",
    "\n",
    "### 3. Modern Implementation with Pipe Operator (Python 3.10+)\n",
    "```python\n",
    "def matrix_vector_mult_py310(matrix: list[list[int | float]], vector: list[int | float]) -> list[float]:\n",
    "    # Same implementation with modern type hint syntax\n",
    "```\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Functionality**: All implementations perform the same matrix-vector multiplication operation.\n",
    "\n",
    "2. **Type Hint Differences**:\n",
    "   - The first implementation restricts inputs to floats only\n",
    "   - The second and third implementations allow both integers and floats\n",
    "   - The second uses `Union[int, float]` for Python 3.7+ compatibility\n",
    "   - The third uses `int | float` syntax for cleaner code in Python 3.10+\n",
    "\n",
    "3. **Type Equivalence**: Despite different internal representations (`typing._UnionGenericAlias` vs `types.UnionType`), both union syntaxes are functionally equivalent.\n",
    "\n",
    "4. **Best Practices**:\n",
    "   - Always check matrix and vector dimensions before performing operations\n",
    "   - Raise specific exceptions (ValueError) rather than returning error codes\n",
    "   - Use descriptive variable names (e.g., `m_ij` and `v_j` instead of `a` and `b`)\n",
    "   - Include proper type hints and docstrings\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "**For Python 3.10+ projects**: Use the pipe operator syntax (`int | float`) for better readability.\n",
    "\n",
    "**For Python 3.7-3.9 compatibility**: Use the `Union[int, float]` syntax.\n",
    "\n",
    "**For production code**: Consider using NumPy for better performance and more comprehensive matrix operations:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def matrix_vector_mult_numpy(matrix: np.ndarray, vector: np.ndarray) -> np.ndarray:\n",
    "    return matrix @ vector  # Using the @ operator for matrix multiplication\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72279536",
   "metadata": {},
   "source": [
    "# Matrix-Vector Operations for Quantitative Finance\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook explores implementations of matrix-vector multiplication, a fundamental operation in quantitative finance. We present multiple implementations with increasing sophistication, from basic Python to optimized NumPy versions, with a focus on:\n",
    "\n",
    "1. **Mathematical correctness** - Ensuring proper dimension validation and accurate calculations\n",
    "2. **Type safety** - Supporting both integer and floating-point inputs with proper type hints\n",
    "3. **Performance optimization** - Comparing naive implementations with vectorized operations\n",
    "4. **Financial applications** - Connecting these operations to real-world quantitative finance use cases\n",
    "\n",
    "While matrix-vector multiplication may seem basic, it forms the foundation of numerous financial models, from portfolio optimization to risk management and derivatives pricing. Implementing these operations correctly and efficiently is critical for developing robust financial software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51cbe1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic implementation result: [5, 11]\n"
     ]
    }
   ],
   "source": [
    "# Basic Implementation (Python 3.7+)\n",
    "def matrix_vector_mult(matrix: list[list[float]], vector: list[float]) -> list[float]:\n",
    "    \"\"\"\n",
    "    Multiply a matrix by a vector.\n",
    "    \n",
    "    Args:\n",
    "        matrix: A list of lists representing a matrix\n",
    "        vector: A list representing a vector\n",
    "        \n",
    "    Returns:\n",
    "        A list representing the resulting vector\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the dimensions are incompatible\n",
    "    \"\"\"\n",
    "    # Check if matrix is empty\n",
    "    if not matrix:\n",
    "        return []\n",
    "        \n",
    "    # Check for dimension compatibility\n",
    "    if len(matrix[0]) != len(vector):\n",
    "        raise ValueError(f\"Incompatible dimensions: matrix has {len(matrix[0])} columns but vector has {len(vector)} elements\")\n",
    "    \n",
    "    return [sum(m_ij * v_j for m_ij, v_j in zip(row, vector)) for row in matrix]\n",
    "\n",
    "# Test the basic implementation\n",
    "try:\n",
    "    A = [[1, 2], [3, 4]]\n",
    "    v = [1, 2]\n",
    "    result = matrix_vector_mult(A, v)\n",
    "    print(f\"Basic implementation result: {result}\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94153d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved implementation result: [6.0, 11.4]\n",
      "Result element types: ['float', 'float']\n"
     ]
    }
   ],
   "source": [
    "# Improved Implementation with Union Type (Python 3.7+)\n",
    "from typing import Union, List\n",
    "\n",
    "Numeric = Union[int, float]  # Type alias for numbers that can be either int or float\n",
    "\n",
    "def matrix_vector_mult_improved(matrix: List[List[Numeric]], vector: List[Numeric]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Multiply a matrix by a vector, supporting both integers and floats.\n",
    "    \n",
    "    Args:\n",
    "        matrix: A list of lists representing a matrix (elements can be int or float)\n",
    "        vector: A list representing a vector (elements can be int or float)\n",
    "        \n",
    "    Returns:\n",
    "        A list representing the resulting vector (elements will be float)\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the dimensions are incompatible\n",
    "    \"\"\"\n",
    "    # Check if matrix is empty\n",
    "    if not matrix:\n",
    "        return []\n",
    "        \n",
    "    # Check for dimension compatibility\n",
    "    if len(matrix[0]) != len(vector):\n",
    "        raise ValueError(f\"Incompatible dimensions: matrix has {len(matrix[0])} columns but vector has {len(vector)} elements\")\n",
    "    \n",
    "    return [sum(m_ij * v_j for m_ij, v_j in zip(row, vector)) for row in matrix]\n",
    "\n",
    "# Test with mixed integer and float values\n",
    "try:\n",
    "    A_mixed = [[1, 2.5], [3, 4.2]]  # Mix of int and float\n",
    "    v_mixed = [1, 2.0]  # Mix of int and float\n",
    "    result = matrix_vector_mult_improved(A_mixed, v_mixed)\n",
    "    print(f\"Improved implementation result: {result}\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Let's check the types of the result elements\n",
    "print(f\"Result element types: {[type(x).__name__ for x in result]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2e4982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both type hint styles are equivalent in Python 3.10+\n",
      "Type of Numeric1: <class 'typing._UnionGenericAlias'>\n",
      "Type of Numeric2: <class 'types.UnionType'>\n",
      "Are they equal? True\n",
      "\n",
      "Python 3.10+ implementation result: [6.0, 11.4]\n"
     ]
    }
   ],
   "source": [
    "# Python 3.10+ implementation using pipe operator syntax\n",
    "def matrix_vector_mult_py310(matrix: list[list[int | float]], vector: list[int | float]) -> list[float]:\n",
    "    \"\"\"\n",
    "    Multiply a matrix by a vector, supporting both integers and floats (Python 3.10+ syntax).\n",
    "    \n",
    "    Args:\n",
    "        matrix: A list of lists representing a matrix (elements can be int or float)\n",
    "        vector: A list representing a vector (elements can be int or float)\n",
    "        \n",
    "    Returns:\n",
    "        A list representing the resulting vector (elements will be float)\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the dimensions are incompatible\n",
    "    \"\"\"\n",
    "    # Check if matrix is empty\n",
    "    if not matrix:\n",
    "        return []\n",
    "        \n",
    "    # Check for dimension compatibility\n",
    "    if len(matrix[0]) != len(vector):\n",
    "        raise ValueError(f\"Incompatible dimensions: matrix has {len(matrix[0])} columns but vector has {len(vector)} elements\")\n",
    "    \n",
    "    return [sum(m_ij * v_j for m_ij, v_j in zip(row, vector)) for row in matrix]\n",
    "\n",
    "# Comparison of type hint styles (Python 3.10+ only)\n",
    "try:\n",
    "    # Style 1: Using Union from typing module\n",
    "    from typing import Union\n",
    "    Numeric1 = Union[int, float]\n",
    "\n",
    "    # Style 2: Using pipe operator syntax directly\n",
    "    Numeric2 = int | float\n",
    "\n",
    "    print(\"Both type hint styles are equivalent in Python 3.10+\")\n",
    "    print(f\"Type of Numeric1: {type(Numeric1)}\")\n",
    "    print(f\"Type of Numeric2: {type(Numeric2)}\")\n",
    "    print(f\"Are they equal? {Numeric1 == Numeric2}\")\n",
    "\n",
    "    # Demo with the same test data\n",
    "    A_mixed = [[1, 2.5], [3, 4.2]]\n",
    "    v_mixed = [1, 2.0]\n",
    "    result = matrix_vector_mult_py310(A_mixed, v_mixed)\n",
    "    print(f\"\\nPython 3.10+ implementation result: {result}\")\n",
    "    \n",
    "except (ValueError, SyntaxError) as e:\n",
    "    print(f\"Error: {e}\\nThis might indicate you're using a Python version below 3.10\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16839ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy result: [ 6.  11.4]\n",
      "NumPy result type: <class 'numpy.ndarray'>\n",
      "NumPy element types: float64\n",
      "\n",
      "Manual implementation result: [6.0, 11.4]\n",
      "Are results equal? True\n",
      "\n",
      "Performance comparison on 1000x1000 matrix:\n",
      "NumPy implementation: 0.000256 seconds\n",
      "Python 3.10+ implementation: 0.050373 seconds\n",
      "NumPy is 196.5x faster\n"
     ]
    }
   ],
   "source": [
    "# Final recommended implementation using NumPy for production code\n",
    "try:\n",
    "    import numpy as np\n",
    "    \n",
    "    def matrix_vector_mult_numpy(matrix: np.ndarray, vector: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Multiply a matrix by a vector using NumPy for optimized performance.\n",
    "        \n",
    "        Args:\n",
    "            matrix: A NumPy ndarray representing a matrix\n",
    "            vector: A NumPy ndarray representing a vector\n",
    "            \n",
    "        Returns:\n",
    "            A NumPy ndarray representing the resulting vector\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the dimensions are incompatible (handled by NumPy)\n",
    "        \"\"\"\n",
    "        return matrix @ vector  # Using the @ operator for matrix multiplication\n",
    "    \n",
    "    # Test with the same data\n",
    "    A_np = np.array([[1, 2.5], [3, 4.2]])\n",
    "    v_np = np.array([1, 2.0])\n",
    "    \n",
    "    result_np = matrix_vector_mult_numpy(A_np, v_np)\n",
    "    print(f\"NumPy result: {result_np}\")\n",
    "    print(f\"NumPy result type: {type(result_np)}\")\n",
    "    print(f\"NumPy element types: {result_np.dtype}\")\n",
    "    \n",
    "    # Compare with our manual implementation (make sure matrix_vector_mult_py310 is defined)\n",
    "    try:\n",
    "        result_manual = matrix_vector_mult_py310(A_np.tolist(), v_np.tolist())\n",
    "        print(f\"\\nManual implementation result: {result_manual}\")\n",
    "        print(f\"Are results equal? {np.allclose(result_np, result_manual)}\")\n",
    "    except NameError:\n",
    "        # Fallback to the improved implementation if Python 3.10+ version is not available\n",
    "        result_manual = matrix_vector_mult_improved(A_np.tolist(), v_np.tolist())\n",
    "        print(f\"\\nFallback to improved implementation result: {result_manual}\")\n",
    "        print(f\"Are results equal? {np.allclose(result_np, result_manual)}\")\n",
    "    \n",
    "    # Performance comparison (optional)\n",
    "    import time\n",
    "    \n",
    "    # Create larger matrices for performance testing\n",
    "    large_A = np.random.rand(1000, 1000)\n",
    "    large_v = np.random.rand(1000)\n",
    "    \n",
    "    # Time NumPy implementation\n",
    "    start = time.time()\n",
    "    _ = matrix_vector_mult_numpy(large_A, large_v)\n",
    "    numpy_time = time.time() - start\n",
    "    \n",
    "    # Convert to lists for our implementation\n",
    "    large_A_list = large_A.tolist()\n",
    "    large_v_list = large_v.tolist()\n",
    "    \n",
    "    # Time our implementation (using the most advanced one available)\n",
    "    try:\n",
    "        # Try to use Python 3.10+ implementation\n",
    "        start = time.time()\n",
    "        _ = matrix_vector_mult_py310(large_A_list, large_v_list)\n",
    "        manual_time = time.time() - start\n",
    "        implementation = \"Python 3.10+ implementation\"\n",
    "    except NameError:\n",
    "        # Fallback to the improved implementation\n",
    "        start = time.time()\n",
    "        _ = matrix_vector_mult_improved(large_A_list, large_v_list)\n",
    "        manual_time = time.time() - start\n",
    "        implementation = \"Improved implementation (Union type)\"\n",
    "    \n",
    "    print(f\"\\nPerformance comparison on 1000x1000 matrix:\")\n",
    "    print(f\"NumPy implementation: {numpy_time:.6f} seconds\")\n",
    "    print(f\"{implementation}: {manual_time:.6f} seconds\")\n",
    "    print(f\"NumPy is {manual_time/numpy_time:.1f}x faster\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"NumPy is not installed. For production code, consider installing NumPy:\")\n",
    "    print(\"pip install numpy\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during NumPy comparison: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb294d1",
   "metadata": {},
   "source": [
    "## Applications in Quantitative Finance\n",
    "\n",
    "Matrix-vector multiplication is fundamental to many quantitative finance applications:\n",
    "\n",
    "1. **Portfolio Optimization**\n",
    "   - Calculating portfolio returns: $r_p = w^T r$ where $w$ is the weight vector and $r$ is the returns vector\n",
    "   - Computing portfolio variance: $\\sigma_p^2 = w^T \\Sigma w$ where $\\Sigma$ is the covariance matrix\n",
    "\n",
    "2. **Risk Management**\n",
    "   - Value at Risk (VaR) calculations involving matrix operations\n",
    "   - Stress testing scenarios with multiple risk factors\n",
    "\n",
    "3. **Derivatives Pricing**\n",
    "   - Finite difference methods for option pricing (Black-Scholes PDE)\n",
    "   - Monte Carlo simulations with correlated risk factors\n",
    "\n",
    "4. **Factor Models**\n",
    "   - Computing factor exposures and returns\n",
    "   - Risk decomposition across factors\n",
    "\n",
    "5. **Time Series Analysis**\n",
    "   - Vector autoregressive (VAR) models\n",
    "   - Principal Component Analysis (PCA) for yield curve modeling\n",
    "\n",
    "6. **Machine Learning in Finance**\n",
    "   - Neural network layers (each layer performs matrix operations)\n",
    "   - Deep learning models for option pricing and risk modeling\n",
    "   - Reinforcement learning for trading strategies\n",
    "\n",
    "The optimized implementations are particularly important in finance where:\n",
    "   - Large datasets are common (market data, portfolios with many assets)\n",
    "   - Performance is critical (real-time pricing, high-frequency trading)\n",
    "   - Accuracy is essential (risk calculations, regulatory reporting)\n",
    "   \n",
    "**NumPy vs PyTorch:** While NumPy provides excellent performance for standard operations, PyTorch offers additional benefits for modern quantitative finance applications:\n",
    "   - GPU acceleration for computationally intensive tasks\n",
    "   - Automatic differentiation for optimization problems\n",
    "   - Integration with deep learning pipelines for complex financial modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf4bed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch result: tensor([ 6.0000, 11.4000])\n",
      "PyTorch result type: <class 'torch.Tensor'>\n",
      "PyTorch element types: torch.float32\n",
      "\n",
      "NumPy result: [ 6.  11.4]\n",
      "Are PyTorch and NumPy results equal? True\n",
      "\n",
      "Performance comparison on 10000x10000 matrix:\n",
      "NumPy implementation: 0.016367 seconds\n",
      "PyTorch CPU implementation: 0.011830 seconds\n",
      "\n",
      "Performance comparison on 10000x10000 matrix:\n",
      "NumPy implementation: 0.016367 seconds\n",
      "PyTorch CPU implementation: 0.011830 seconds\n",
      "PyTorch GPU implementation: 0.002339 seconds\n",
      "GPU is 7.0x faster than NumPy\n",
      "PyTorch GPU implementation: 0.002339 seconds\n",
      "GPU is 7.0x faster than NumPy\n"
     ]
    }
   ],
   "source": [
    "# PyTorch implementation for advanced machine learning applications in finance\n",
    "try:\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import time\n",
    "    \n",
    "    def matrix_vector_mult_pytorch(matrix: torch.Tensor, vector: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Multiply a matrix by a vector using PyTorch.\n",
    "        \n",
    "        Args:\n",
    "            matrix: A PyTorch tensor representing a matrix\n",
    "            vector: A PyTorch tensor representing a vector\n",
    "            \n",
    "        Returns:\n",
    "            A PyTorch tensor representing the resulting vector\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the dimensions are incompatible (handled by PyTorch)\n",
    "        \"\"\"\n",
    "        return torch.matmul(matrix, vector)  # Using the matmul function for matrix multiplication\n",
    "    \n",
    "    # Test with the same data\n",
    "    A_pt = torch.tensor([[1.0, 2.5], [3.0, 4.2]])\n",
    "    v_pt = torch.tensor([1.0, 2.0])\n",
    "    \n",
    "    result_pt = matrix_vector_mult_pytorch(A_pt, v_pt)\n",
    "    print(f\"PyTorch result: {result_pt}\")\n",
    "    print(f\"PyTorch result type: {type(result_pt)}\")\n",
    "    print(f\"PyTorch element types: {result_pt.dtype}\")\n",
    "    \n",
    "    # Compare with NumPy implementation\n",
    "    A_np = np.array([[1, 2.5], [3, 4.2]])\n",
    "    v_np = np.array([1, 2.0])\n",
    "    \n",
    "    result_np = matrix_vector_mult_numpy(A_np, v_np)\n",
    "    print(f\"\\nNumPy result: {result_np}\")\n",
    "    print(f\"Are PyTorch and NumPy results equal? {np.allclose(result_pt.numpy(), result_np)}\")\n",
    "    \n",
    "    # Performance comparison between PyTorch and NumPy\n",
    "    # Create larger matrices for performance testing\n",
    "    large_size = 10000\n",
    "    \n",
    "    # NumPy matrices\n",
    "    large_A_np = np.random.rand(large_size, large_size)\n",
    "    large_v_np = np.random.rand(large_size)\n",
    "    \n",
    "    # PyTorch matrices (on CPU for fair comparison)\n",
    "    large_A_pt = torch.tensor(large_A_np, dtype=torch.float32)\n",
    "    large_v_pt = torch.tensor(large_v_np, dtype=torch.float32)\n",
    "    \n",
    "    # Time NumPy implementation\n",
    "    start = time.time()\n",
    "    _ = matrix_vector_mult_numpy(large_A_np, large_v_np)\n",
    "    numpy_time = time.time() - start\n",
    "    \n",
    "    # Time PyTorch implementation (on CPU)\n",
    "    start = time.time()\n",
    "    _ = matrix_vector_mult_pytorch(large_A_pt, large_v_pt)\n",
    "    pytorch_cpu_time = time.time() - start\n",
    "    \n",
    "    print(f\"\\nPerformance comparison on {large_size}x{large_size} matrix:\")\n",
    "    print(f\"NumPy implementation: {numpy_time:.6f} seconds\")\n",
    "    print(f\"PyTorch CPU implementation: {pytorch_cpu_time:.6f} seconds\")\n",
    "    \n",
    "    # Check if CUDA (GPU) is available and run GPU comparison\n",
    "    if torch.cuda.is_available():\n",
    "        # Move tensors to GPU\n",
    "        large_A_pt_gpu = large_A_pt.cuda()\n",
    "        large_v_pt_gpu = large_v_pt.cuda()\n",
    "        \n",
    "        # Warm-up for GPU (first CUDA operation includes initialization overhead)\n",
    "        _ = matrix_vector_mult_pytorch(large_A_pt_gpu, large_v_pt_gpu)\n",
    "        torch.cuda.synchronize()  # Wait for GPU operations to finish\n",
    "        \n",
    "        # Time PyTorch implementation on GPU\n",
    "        start = time.time()\n",
    "        _ = matrix_vector_mult_pytorch(large_A_pt_gpu, large_v_pt_gpu)\n",
    "        torch.cuda.synchronize()  # Wait for GPU operations to finish\n",
    "        pytorch_gpu_time = time.time() - start\n",
    "        \n",
    "        print(f\"PyTorch GPU implementation: {pytorch_gpu_time:.6f} seconds\")\n",
    "        print(f\"GPU is {numpy_time/pytorch_gpu_time:.1f}x faster than NumPy\")\n",
    "    else:\n",
    "        print(\"\\nGPU not available. For maximum performance in financial applications, consider using a CUDA-enabled GPU.\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"PyTorch is not installed. For advanced machine learning applications in finance, consider installing PyTorch:\")\n",
    "    print(\"pip install torch\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during PyTorch comparison: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb6b1c7",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we've examined various implementations of matrix-vector multiplication, from basic Python list comprehensions to optimized NumPy and PyTorch operations. The progression demonstrates important software engineering concepts like type safety, error handling, and performance optimization - all within the context of quantitative finance applications.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Type Safety**: Using appropriate type hints improves code robustness and documentation.\n",
    "2. **Performance**: The NumPy implementation is typically 10-100x faster than manual implementations, while PyTorch with GPU acceleration can provide even greater speedups.\n",
    "3. **Error Handling**: Proper dimension checking and error messages are essential for robust financial code.\n",
    "4. **Financial Context**: Understanding the mathematical operations behind financial models helps in implementing them correctly.\n",
    "5. **Hardware Acceleration**: GPU support through PyTorch enables handling extremely large datasets common in modern finance.\n",
    "\n",
    "### Further Exploration\n",
    "\n",
    "This notebook is part of a larger collection of quantitative finance tools. To explore more implementations, check out the repository structure:\n",
    "\n",
    "```\n",
    "quantitative-finance-tools/\n",
    "├── linear-algebra/           # Linear algebra operations for financial models\n",
    "│   ├── matrix_vector_operations.ipynb  # This notebook\n",
    "│   └── (future notebooks)    # Matrix decompositions, eigenvalue analysis, etc.\n",
    "├── statistical-methods/      # (Future) Statistical tools for financial analysis\n",
    "├── portfolio-theory/         # (Future) Portfolio optimization implementations\n",
    "└── derivatives-pricing/      # (Future) Option pricing and risk models\n",
    "```\n",
    "\n",
    "To contribute to this repository or suggest improvements, please follow the guidelines in the main README.md file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
